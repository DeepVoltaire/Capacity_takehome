{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33426877-b84c-4e2b-bc76-d68bbd76d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tifffile pandas matplotlib geopandas rasterio albumentations #opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43a140-a617-489b-ae20-3818d5ee541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import tifffile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import shape\n",
    "import glob\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import json\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "red_to_green = LinearSegmentedColormap.from_list(\"RedGreen\", [\"red\", \"green\"])\n",
    "\n",
    "from src.visualize import visualize_s2_concat_bands_path, visualize_s1_path, scale_img, visualize_ls_concat_bands_path, visualize_cb_mux_path, visualize_cb_wpm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79964fc1-db1e-4bcc-82be-c2db8cb805d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# from pathlib import Path\n",
    "\n",
    "# for src_folder in glob.glob(\"1*\"):\n",
    "#     event_id = src_folder.split(\"/\")[-1]\n",
    "#     dst_folder = Path(f\"data/{event_id}\")  # will be created if it doesn't exist\n",
    "\n",
    "#     # copies entire directory tree; preserves metadata (copy2)\n",
    "#     shutil.copytree(\n",
    "#         src_folder,\n",
    "#         dst_folder,\n",
    "#         dirs_exist_ok=True,                     # requires Python 3.8+\n",
    "#         copy_function=shutil.copy2,             # preserve mtime/permissions\n",
    "#         symlinks=False,                         # set True to keep symlinks as symlinks\n",
    "#         ignore=shutil.ignore_patterns('__pycache__', '*.pyc', '.DS_Store')\n",
    "#     )\n",
    "\n",
    "# for src_folder in glob.glob(\"1*\"):\n",
    "#     shutil.rmtree(src_folder)\n",
    "\n",
    "# for path in glob.glob(\"README_*\"):\n",
    "#     shutil.move(path, f\"data/{path}\")\n",
    "# shutil.move(\"DATASET_OVERVIEW.md\", f\"data/DATASET_OVERVIEW.md\")\n",
    "# shutil.move(\"dataset_analysis.json\", \"data/dataset_analysis.json\")\n",
    "# shutil.move(\"mapbiomas_alerts.geojson\", \"data/mapbiomas_alerts.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580886c-1612-40ce-9c25-25bce8c505f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dataset_analysis.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    dataset_analysis = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2db593-3844-469c-852c-755aa65d91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(\"data/mapbiomas_alerts.geojson\")\n",
    "events_sorted_by_area = df.sort_values(\"areaHa\", ascending=False)[\"alertCode\"].tolist()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71c389a-972f-475d-b9b4-df3a8217e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"areaHa\", ascending=False).iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94533480-9356-4d1d-b8ec-8eaedb72070b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json.loads(open(\"data/1389384/sentinel2/1389384_sentinel2_S2-16D_V2_018015_20250218_20250218_bands.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef21bee-8fdf-4778-908a-ac8b28a1517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alertCode = \"1389384\"\n",
    "with rasterio.open(f\"data/1389384/sentinel2/1389384_sentinel2_S2-16D_V2_018015_20250218_20250218.tif\") as src:\n",
    "    data = src.read()  # Shape: (bands, height, width)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bacf67-c186-4e48-8829-bef581531664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_ids = [k.split(\"/\")[-1] for k in sorted(glob.glob(\"data/1*\"))]\n",
    "len(event_ids)#, event_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c7b46-685c-4ed1-b0bc-2125a0bbeef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"alertCode\"]==1387975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc69df-0219-4480-be7c-f0e763acbdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted([k for k in glob.glob(\"data/1390023/sentinel2/*L2A*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1dd5f-806b-4629-a6fb-a58a628216fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bands = [\n",
    "#     \"red\",\n",
    "#     \"blue\",\n",
    "#     \"green\",\n",
    "#     \"nir08\",\n",
    "#     \"st_qa\",\n",
    "#     \"lwir11\",\n",
    "#     \"swir16\",\n",
    "#     \"swir22\",\n",
    "#     \"coastal\",\n",
    "#     \"st_drad\",\n",
    "#     \"st_emis\",\n",
    "#     \"st_emsd\",\n",
    "#     \"st_trad\",\n",
    "#     \"st_urad\",\n",
    "#     \"qa_pixel\",\n",
    "#     \"st_atran\",\n",
    "#     \"st_cdist\",\n",
    "#     \"qa_radsat\",\n",
    "#     \"qa_aerosol\"\n",
    "#   ]\n",
    "# bands.index(\"swir22\"), bands.index(\"nir08\"), bands.index(\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f6e52-5547-4459-ac71-f5221cebe061",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6995cc-a1a7-4f29-bf54-08429779c862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = tifffile.imread('data/1389891/landsat/1389891_landsat_LC09_L2SP_227066_20250427_20250428_02_T1_20250427.tif').astype(np.float32)\n",
    "img = img[:, :, [7, 3, 0]] * 0.0000275 - 0.2\n",
    "# img.mean(axis=(0,1))\n",
    "img = np.clip(img / 0.5, 0, 1)  # normalize for display\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7d9e2-2da0-4c40-8f07-1b0177409078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nothing_count = 0\n",
    "for event_id in events_sorted_by_area:\n",
    "# for event_id in [k.split(\"/\")[-1] for k in glob.glob(f\"data/*\")]:\n",
    "    if len(glob.glob(f\"data/{event_id}/*/*.tif\")) == 0:\n",
    "        print(f\"data/{event_id}/*/*.tif\")\n",
    "        nothing_count += 1\n",
    "    if len(glob.glob(f\"data/{event_id}/*/*.tif\")) < 10:\n",
    "        print(glob.glob(f\"data/{event_id}/*/*.tif\"))\n",
    "    # else:\n",
    "    #     print(glob.glob(f\"data/{event_id}/*/*.tif\"))\n",
    "nothing_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2203a-fc18-4b8a-abe3-77aba4227470",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b0dc5-7ac1-4453-82d3-bccceae33ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\n",
    "    \"B01\",\n",
    "    \"B02\",\n",
    "    \"B03\",\n",
    "    \"B04\",\n",
    "    \"B05\",\n",
    "    \"B06\",\n",
    "    \"B07\",\n",
    "    \"B08\",\n",
    "    \"B09\",\n",
    "    \"B11\",\n",
    "    \"B12\",\n",
    "    \"B8A\",\n",
    "    \"SCL\"\n",
    "  ]\n",
    "bands.index(\"B12\"), bands.index(\"B08\"), bands.index(\"B04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458f994-ed7a-4133-a1eb-f9f6daa8a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tifffile.imread(path)\n",
    "img.shape, img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2090c-1add-4810-8540-6fd183a3a98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede6914-0e37-4af0-adb8-bc6bc68c069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3cec5f-008d-493e-afa9-41595f7272ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.min(axis=(0,1)), img.max(axis=(0,1)), img.mean(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae6eda-b0da-4e12-ae6b-0833755fec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[:, :, 1] > 2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6a87c-0d88-4259-afc8-cf3596a02b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scale_img(img[:, :, [10, 7, 3]], np.array([0, 0, 0]), np.array([3500, 3500, 3500])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0342e-17fd-43bf-af3a-5d2b31e50dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ax_empty(ax):\n",
    "    \"\"\"Check if a matplotlib axis is empty.\"\"\"\n",
    "    return not (ax.lines or ax.collections or ax.patches or ax.images)\n",
    "\n",
    "max_cloud_nodata = 100\n",
    "for event_id in events_sorted_by_area[:]:\n",
    "    # rand_int = np.random.randint(len(events_sorted_by_area))\n",
    "    # rand_int = k\n",
    "    # event_id = events_sorted_by_area[rand_int]\n",
    "    s2_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel2/*L2A*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k])\n",
    "    s2_16d_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel2/*16D*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k])\n",
    "    s1_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel1/*.tif\") if not \"_nrpb\" in k and not \"_rfdi\" in k and not \"_rvi\" in k and not \"_vv_vh_ratio\" in k])\n",
    "    ls_paths = sorted([k for k in glob.glob(f\"data/{event_id}/landsat/*_L2SP_*.tif\") if not \"_nbr\" in k and not \"_ndwi\" in k and not \"_ndvi\" in k])\n",
    "    cb_wpm_paths = sorted([k for k in glob.glob(f\"data/{event_id}/cbers4a/*_WPM_*.tif\") if not \"_ndvi\" in k])\n",
    "    cb_mux_paths = sorted([k for k in glob.glob(f\"data/{event_id}/cbers4a/*_MUX_*.tif\") if not \"_ndvi\" in k])\n",
    "    print(f\"{event_id}: {len(s2_paths):2} S2 L2A, {len(s2_16d_paths):2} S2 16D,{len(s1_paths):2} S1, {len(ls_paths):2} LS L2SP, {len(cb_wpm_paths):2} CB WPM, {len(cb_mux_paths):2} CB MUX\")\n",
    "    paths = s2_paths + s1_paths + ls_paths + cb_wpm_paths + cb_mux_paths + s2_16d_paths\n",
    "    if len(paths) == 0:\n",
    "        continue\n",
    "    # continue\n",
    "    mask_path = glob.glob(f\"data/{event_id}/*_mask.tif\")[0]\n",
    "    \n",
    "    # Sort by the date right before the .tif\n",
    "    paths = sorted(paths, key=lambda p: datetime.strptime(p.split('_')[-1].split('.')[0], \"%Y%m%d\"))\n",
    "    imgs_to_show = []\n",
    "    titles = []\n",
    "    for path in paths:\n",
    "        what_to_do_string = \"SKIP\"\n",
    "        img_orig = tifffile.imread(path)\n",
    "        date = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "        date_str = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "        if \"L2A\" in path:\n",
    "            img_orig = img_orig.astype(np.float32)\n",
    "            img_orig = img_orig - 1000\n",
    "            img_orig[img_orig < 0] = 0\n",
    "            # print(img_orig[:, :, 1:-2].min(axis=(0, 1)), img_orig[:, :, 1:-2].max(axis=(0, 1)))\n",
    "            clouds_perc = 100 * (img_orig[:, :, 2] > 2400).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            nodata_perc = 100 * (img_orig[:, :, 2] == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            if clouds_perc + nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"S2 L2A {date_str}: {clouds_perc:5.1f}% Clouds, {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if clouds_perc + nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            img = visualize_s2_concat_bands_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"S2 L2A: {date_str}\\n{clouds_perc:.1f}% Clouds, {nodata_perc:.1f}% Nodata\")\n",
    "        elif \"16D\" in path:\n",
    "            clouds_perc = 100 * (img_orig[:, :, 1] > 2400).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            nodata_perc = 100 * (img_orig[:, :, 1] == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            if clouds_perc + nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"S2 16D {date_str}: {clouds_perc:5.1f}% Clouds, {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if clouds_perc + nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            img = visualize_s2_concat_bands_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"S2 16D: {date_str}\\n{clouds_perc:.1f}% Clouds, {nodata_perc:.1f}% Nodata\")\n",
    "        elif \"_L2SP\" in path:\n",
    "            qa = img_orig[:, :, -5].copy()\n",
    "            # bit positions for dilated, cirrus, cloud\n",
    "            CLOUD_BITS = (1, 2, 3)\n",
    "            cloudmask = np.zeros_like(qa, dtype=bool)\n",
    "            for b in CLOUD_BITS:\n",
    "                cloudmask |= np.bitwise_and(qa, 1 << b) != 0\n",
    "\n",
    "            clouds_perc = 100 * (cloudmask.sum() / (img_orig.shape[0] * img_orig.shape[1]))\n",
    "            nodata_perc = 100 * (img_orig[:, :, 2] == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            if clouds_perc + nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"LS     {date_str}: {clouds_perc:5.1f}% Clouds, {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if clouds_perc + nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            img = visualize_ls_concat_bands_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"LS: {date_str}\\n{clouds_perc:.1f}% Clouds, {nodata_perc:.1f}% Nodata\")\n",
    "        elif \"_WPM_\" in path:\n",
    "            clouds_perc = 100 * (img_orig[:, :, 2] > 35000).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            nodata_perc = 100 * (img_orig[:, :, 0] == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            if clouds_perc + nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"WPM    {date_str}: {clouds_perc:5.1f}% Clouds, {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if clouds_perc + nodata_perc > 175:\n",
    "                continue\n",
    "            img = visualize_cb_wpm_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"WPM: {date_str}\\n{clouds_perc:.1f}% Clouds, {nodata_perc:.1f}% Nodata\")\n",
    "        elif \"_MUX_\" in path:\n",
    "            clouds_perc = 100 * (img_orig[:, :, 0] > 55).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            nodata_perc = 100 * (img_orig[:, :, 0] == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            if clouds_perc + nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"MUX    {date_str}: {clouds_perc:5.1f}% Clouds, {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if clouds_perc + nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            img = visualize_cb_mux_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"MUX: {date_str}\\n{clouds_perc:.1f}% Clouds, {nodata_perc:.1f}% Nodata\")\n",
    "        else:\n",
    "            nodata_perc = 100 * (img_orig[:, :, 0] == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            if nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"S1     {date_str}: {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            img = visualize_s1_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"S1: {date_str}\\n{nodata_perc:.1f}% Nodata\")\n",
    "        imgs_to_show.append(img)\n",
    "\n",
    "    if len(imgs_to_show) > 0:\n",
    "        rows = (len(imgs_to_show) // 5) + 1\n",
    "        cols =  (len(imgs_to_show) // rows) + 1\n",
    "        f, ax = plt.subplots(rows, max(2, cols), figsize=(30, 7 * rows))\n",
    "        ax = ax.flatten()\n",
    "        for j in range(len(imgs_to_show)):\n",
    "            ax[j].imshow(imgs_to_show[j])\n",
    "            ax[j].set_title(titles[j], fontsize=15)\n",
    "\n",
    "        mask = rasterio.open(mask_path).read(1)\n",
    "        date = mask_path.split(\"/\")[-1].split('_')[1]\n",
    "        date_str = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "        if mask.shape[0] != img.shape[1]:\n",
    "            mask = cv2.resize(mask, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        ax[j+1].imshow(img)\n",
    "        ax[j+1].imshow(np.ma.masked_where(mask != 255, mask), cmap=\"cool\" if \"_MUX_\" in path else \"autumn\", alpha=0.5)\n",
    "        ax[j+1].set_title(f\"{date_str}\", fontsize=15)\n",
    "        # Hide empty axes\n",
    "        for ax_idx in range(len(ax)):\n",
    "            if is_ax_empty(ax[ax_idx]):  # type: ignore\n",
    "                ax[ax_idx].set_visible(False)  # type: ignore\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7e049-3a70-4241-9a24-69d05cc2be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaeb483-bcab-4212-941b-2510e47c35c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d87e8a-526d-4d80-94e7-e6b7efb21cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S2 16D IS SUPER MESSY, DONT USE\n",
    "def is_ax_empty(ax):\n",
    "    \"\"\"Check if a matplotlib axis is empty.\"\"\"\n",
    "    return not (ax.lines or ax.collections or ax.patches or ax.images)\n",
    "\n",
    "max_cloud_nodata = 100\n",
    "for event_id in events_sorted_by_area[:]:\n",
    "    # rand_int = np.random.randint(len(events_sorted_by_area))\n",
    "    # rand_int = k\n",
    "    # event_id = events_sorted_by_area[rand_int]\n",
    "    s2_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel2/*L2A*_ndvi.tif\")])\n",
    "    s2_16d_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel2/*16D*_ndvi.tif\")])\n",
    "    s1_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel1/*.tif\") if not \"_nrpb\" in k and not \"_rfdi\" in k and not \"_rvi\" in k and not \"_vv_vh_ratio\" in k])\n",
    "    ls_paths = sorted([k for k in glob.glob(f\"data/{event_id}/landsat/*_L2SP_*ndvi.tif\")])\n",
    "    cb_wpm_paths = sorted([k for k in glob.glob(f\"data/{event_id}/cbers4a/*_WPM_*_ndvi.tif\")])\n",
    "    cb_mux_paths = sorted([k for k in glob.glob(f\"data/{event_id}/cbers4a/*_MUX_*_ndvi.tif\")])\n",
    "    print(f\"{event_id}: {len(s2_paths)} S2 L2A, {len(s1_paths)} S1, {len(ls_paths)} LS L2SP, {len(cb_wpm_paths)} CB WPM, {len(cb_mux_paths)} CB MUX\")\n",
    "    paths = s2_paths + s1_paths + ls_paths + cb_wpm_paths + cb_mux_paths + s2_16d_paths\n",
    "    if len(paths) == 0:\n",
    "        continue\n",
    "    mask_path = glob.glob(f\"data/{event_id}/*_mask.tif\")[0]\n",
    "    \n",
    "    # Sort by the date right before the .tif\n",
    "    paths = sorted(paths, key=lambda p: datetime.strptime(p.replace(\"_ndvi\", \"\").split('_')[-1].split('.')[0], \"%Y%m%d\"))\n",
    "    imgs_to_show = []\n",
    "    titles = []\n",
    "    for path in paths:\n",
    "        img_orig = rasterio.open(path).read()\n",
    "        date = path.replace(\"_ndvi\", \"\").split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "        date_str = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "        if \"L2A\" in path:\n",
    "            img_orig = img_orig[0]\n",
    "            # print(img_orig[:, :, 1:-2].min(axis=(0, 1)), img_orig[:, :, 1:-2].max(axis=(0, 1)))\n",
    "            nodata_perc = 100 * (img_orig == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            what_to_do_string = \"SKIP\"\n",
    "            if nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"S2 L2A {date_str}: {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            # img = visualize_s2_concat_bands_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"S2 L2A: {date_str}\\n{nodata_perc:.1f}% Nodata\")\n",
    "        elif \"16D\" in path:\n",
    "            img_orig = img_orig[0]\n",
    "            # clouds_perc = 100 * (img_orig[:, :, 1] > 2400).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            nodata_perc = 100 * (img_orig == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            what_to_do_string = \"SKIP\"\n",
    "            if nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"S2 16D {date_str}: {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            # img = visualize_s2_concat_bands_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"S2 16D: {date_str}\\n{nodata_perc:.1f}% Nodata\")\n",
    "        elif \"_L2SP\" in path:\n",
    "            img_orig = img_orig[0]\n",
    "            nodata_perc = 100 * (img_orig == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            what_to_do_string = \"SKIP\"\n",
    "            if clouds_perc + nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"LS     {date_str}: {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            # img = visualize_ls_concat_bands_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"LS: {date_str}\\n{nodata_perc:.1f}% Nodata\")\n",
    "        elif \"_WPM_\" in path:\n",
    "            img_orig = img_orig[0]\n",
    "            # clouds_perc = 100 * (img_orig[:, :, 2] > 35000).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            nodata_perc = 100 * (img_orig == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            what_to_do_string = \"SKIP\"\n",
    "            if nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"WPM    {date_str}: {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            # img = visualize_cb_wpm_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"WPM: {date_str}\\n{nodata_perc:.1f}% Nodata\")\n",
    "        elif \"_MUX_\" in path:\n",
    "            img_orig = img_orig[0]\n",
    "            # clouds_perc = 100 * (img_orig[:, :, 0] > 55).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            nodata_perc = 100 * (img_orig == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            what_to_do_string = \"SKIP\"\n",
    "            if nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            print(f\"MUX    {date_str}: {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            # img = visualize_cb_mux_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"MUX: {date_str}\\n{nodata_perc:.1f}% Nodata\")\n",
    "        else:\n",
    "            if img_orig.shape[0] < 15:\n",
    "                img_orig = np.transpose(img_orig, (1, 2, 0))\n",
    "            nodata_perc = 100 * (img_orig[:, :, 0] == 0).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "            what_to_do_string = \"SKIP\"\n",
    "            if nodata_perc < max_cloud_nodata:\n",
    "                what_to_do_string = \"NO SKIP\"\n",
    "            date = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            date_str = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "            print(f\"S1     {date_str}: {nodata_perc:5.1f}% Nodata --> {what_to_do_string}\")\n",
    "            if nodata_perc > max_cloud_nodata:\n",
    "                continue\n",
    "            img = visualize_s1_path(path)\n",
    "            ending = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "            titles.append(f\"S1: {date_str}\\n{nodata_perc:.1f}% Nodata\")\n",
    "            imgs_to_show.append(img)\n",
    "            continue\n",
    "        print(img_orig.min(), img_orig.max(), img_orig.mean())\n",
    "        imgs_to_show.append(img_orig)\n",
    "\n",
    "    if len(imgs_to_show) > 0:\n",
    "        rows = (len(imgs_to_show) // 5) + 1\n",
    "        cols =  (len(imgs_to_show) // rows) + 1\n",
    "        f, ax = plt.subplots(rows, max(2, cols), figsize=(30, 7 * rows))\n",
    "        ax = ax.flatten()\n",
    "        for j in range(len(imgs_to_show)):\n",
    "            if \"S1\" in titles[j]:\n",
    "                ax[j].imshow(imgs_to_show[j])\n",
    "            else:\n",
    "                ax[j].imshow(imgs_to_show[j], vmin=-2000, vmax=6000, cmap=red_to_green)\n",
    "            ax[j].set_title(titles[j], fontsize=15)\n",
    "\n",
    "        mask = rasterio.open(mask_path).read(1)\n",
    "        date = mask_path.split(\"/\")[-1].split('_')[1]\n",
    "        date_str = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "        if mask.shape[0] != img.shape[1]:\n",
    "            import cv2\n",
    "            mask = cv2.resize(mask, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "        ax[j+1].imshow(img)\n",
    "        # plt.imshow(np.ma.masked_where(mask != 0, mask), cmap=\"winter\", alpha=0.5)\n",
    "        ax[j+1].imshow(np.ma.masked_where(mask != 255, mask), cmap=\"cool\" if \"_MUX_\" in path else \"autumn\", alpha=0.5)\n",
    "        ax[j+1].set_title(f\"{date_str}\", fontsize=15)\n",
    "        # Hide empty axes\n",
    "        for ax_idx in range(len(ax)):\n",
    "            if is_ax_empty(ax[ax_idx]):  # type: ignore\n",
    "                ax[ax_idx].set_visible(False)  # type: ignore\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a7386-472a-473f-89d9-01ae0ab50831",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask_path in glob.glob(f\"data/*/*_mask.tif\"):\n",
    "    mask = tifffile.imread(mask_path)\n",
    "    print(mask_path, np.unique(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d797ad-7721-4ebe-91eb-7016e5760814",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc1566-7f96-4b8e-b886-7d2f4bb92ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a745b-8328-4bfc-b582-ed8f1fc203c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\n",
    "    \"AOT\",\n",
    "    \"B01\",\n",
    "    \"B02\",\n",
    "    \"B03\",\n",
    "    \"B04\",\n",
    "    \"B05\",\n",
    "    \"B06\",\n",
    "    \"B07\",\n",
    "    \"B08\",\n",
    "    \"B09\",\n",
    "    \"B11\",\n",
    "    \"B12\",\n",
    "    \"B8A\",\n",
    "    \"SCL\",\n",
    "    \"WVP\"\n",
    "]\n",
    "bands.index(\"B12\"), bands.index(\"B08\"), bands.index(\"B04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fff19-9c30-42a7-ae46-8f3e641e7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # S2 16D IS SUPER MESSY, DONT USE\n",
    "# for k in range(5):\n",
    "#     rand_int = np.random.randint(len(event_ids))\n",
    "#     event_id = event_ids[rand_int]\n",
    "#     paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel2/*16D*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k])\n",
    "#     print(f\"{event_id}: {len(paths)} 16D paths\")\n",
    "#     if len(paths) == 0:\n",
    "#         continue\n",
    "    \n",
    "#     # Sort by the date right before the .tif\n",
    "#     paths = sorted(paths, key=lambda p: datetime.strptime(p.split('_')[-1].split('.')[0], \"%Y%m%d\"))\n",
    "#     f, ax = plt.subplots(1, max(2, len(paths)), figsize=(30, 10))\n",
    "#     idx = 0\n",
    "#     for s2_path in paths:\n",
    "#         img_orig = tifffile.imread(s2_path)\n",
    "#         print(img_orig.min(axis=(0, 1)), img_orig.max(axis=(0, 1)))\n",
    "#         img = visualize_s2_concat_bands_path(s2_path)\n",
    "#         ending = s2_path.split(\"/\")[-1]\n",
    "#         ax[idx].imshow(img)\n",
    "#         ax[idx].set_title(f\"{ending[-20:]}\", fontsize=15)\n",
    "#         idx += 1\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc17a8b-bb69-4c14-9d6c-e335e28c07a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e303bdd0-6f9b-49b6-96f3-7801552c21e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ls_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97118bf7-2d08-4db3-8892-67e9f11fb415",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9964d2-5053-4b47-8e92-7d9a69045482",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(event_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc6184-9fc1-419c-a62c-60f0c2fc320e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for count_type in [\"s2_l2a\", \"s2_l2a_ndvi\", \"s2_l2a_gndvi\", \"s2_l2a_ndwi\", \"s2_16d\", \"s2_16d_ndvi\", \"s2_16d_gndvi\", \"s2_16d_ndwi\"]:\n",
    "    counts[count_type] = 0\n",
    "no_s1 = 0\n",
    "for event_id in event_ids:\n",
    "    print(f\"{event_id}\")\n",
    "    s2_paths = glob.glob(f\"data/{event_id}/sentinel2/*\")\n",
    "    tif_paths = glob.glob(f\"data/{event_id}/sentinel2/*.tif\")\n",
    "    if len([k for k in tif_paths if \"_MSIL2A_\" in k]) > 0:\n",
    "        counts[\"s2_l2a\"] += 1\n",
    "    # not \"ndvi\" in k and not \"ndwi\" in k\n",
    "    print(f\"   S2: {len(s2_paths):2} paths\")\n",
    "    s1_paths = glob.glob(f\"data/{event_id}/sentinel1/*.tif\")\n",
    "    if len(s1_paths) == 0:\n",
    "        no_s1 += 1\n",
    "    print(f\"   S1: {len(s1_paths):2} paths\")\n",
    "    # print(s1_paths)\n",
    "    # ls_paths = glob.glob(f\"data/{event_id}/landsat/*\")\n",
    "    # print(f\"   LS: {len(ls_paths):2} paths\")\n",
    "    # cb_paths = glob.glob(f\"data/{event_id}/cbers4a/*\")\n",
    "    # print(f\"   CB: {len(cb_paths):2} paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b59b42-3a51-4725-a65d-82da4f312d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[\"s2_l2a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922a9b3-e167-4e64-b289-3a729feb288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Iterable, Union, Tuple\n",
    "\n",
    "# ---------------------- Config ----------------------\n",
    "BASE_DIR = Path(\"data\")  # change if you want to scan the filesystem\n",
    "SENSORS = [\"sentinel2\", \"sentinel1\", \"landsat\", \"cbers4a\"]\n",
    "\n",
    "# Indices to detect in filenames (lowercase match)\n",
    "INDEX_KEYS = [\"ndvi\", \"gndvi\", \"ndwi\", \"nbr\", \"rvi\", \"rfdi\", \"nrpb\", \"vv_vh_ratio\"]\n",
    "\n",
    "# Optional: pretty labels for combinations\n",
    "SENSOR_ALIASES = {\n",
    "    \"sentinel1\": \"s1\",\n",
    "    \"sentinel2\": \"s2\",\n",
    "    \"landsat\": \"ls\",\n",
    "    \"cbers4a\": \"cbers\",\n",
    "}\n",
    "\n",
    "# ------------------- Helpers ------------------------\n",
    "def is_raster(path: Union[str, Path]) -> bool:\n",
    "    p = str(path).lower()\n",
    "    return p.endswith(\".tif\") and not p.endswith(\".tif.aux.xml\")\n",
    "\n",
    "def get_event_id(path: Union[str, Path]) -> str:\n",
    "    parts = Path(path).parts\n",
    "    try:\n",
    "        i = parts.index(\"data\")\n",
    "        return parts[i + 1]\n",
    "    except (ValueError, IndexError):\n",
    "        m = re.search(r\"data[/\\\\]([^/\\\\]+)[/\\\\]\", str(path))\n",
    "        return m.group(1) if m else \"UNKNOWN\"\n",
    "\n",
    "def get_sensor(path: Union[str, Path]) -> str:\n",
    "    parts = Path(path).parts\n",
    "    try:\n",
    "        i = parts.index(\"data\")\n",
    "        return parts[i + 2]\n",
    "    except (ValueError, IndexError):\n",
    "        m = re.search(r\"data[/\\\\][^/\\\\]+[/\\\\]([^/\\\\]+)[/\\\\]\", str(path))\n",
    "        return m.group(1) if m else \"UNKNOWN\"\n",
    "\n",
    "def detect_index(filename: str) -> Union[str, None]:\n",
    "    base = os.path.basename(filename).lower()\n",
    "    for key in INDEX_KEYS:\n",
    "        if re.search(rf\"(^|[^a-z]){re.escape(key)}($|[^a-z])\", base):\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "def detect_raw_type(sensor: str, filename: str) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Heuristics for \"raw\" product-type buckets per sensor family.\n",
    "    Extend/adjust to your naming conventions if needed.\n",
    "    \"\"\"\n",
    "    base = os.path.basename(filename)\n",
    "\n",
    "    if sensor == \"sentinel2\":\n",
    "        if \"S2-16D\" in base:\n",
    "            return \"16D\"\n",
    "        if \"MSIL2A\" in base:\n",
    "            return \"L2A\"\n",
    "        return None\n",
    "\n",
    "    if sensor == \"landsat\":\n",
    "        if \"LANDSAT-16D\" in base:\n",
    "            return \"16D\"\n",
    "        if re.search(r\"L[CT]0[0-9]_L2SP\", base):  # LC08/LC09 L2SP\n",
    "            return \"L2SP\"\n",
    "        return None\n",
    "\n",
    "    if sensor == \"sentinel1\":\n",
    "        if re.search(r\"S1[AB]_IW_GRDH\", base):\n",
    "            return \"GRDH\"\n",
    "        return None\n",
    "\n",
    "    if sensor == \"cbers4a\":\n",
    "        if \"MUX_CBERS_4A_MUX_RAW\" in base:\n",
    "            return \"MUX_RAW\"\n",
    "        if \"WPM_CBERS4A_WPM_PCA\" in base:\n",
    "            return \"WPM_PCA\"\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "\n",
    "def iter_paths(root: Union[str, Path]) -> Iterable[Path]:\n",
    "    root = Path(root)\n",
    "    if root.is_dir():\n",
    "        yield from root.rglob(\"*\")\n",
    "    else:\n",
    "        # If 'root' is a file containing paths, adapt here to read lines\n",
    "        yield root\n",
    "\n",
    "# ------------------- Core logic ---------------------\n",
    "def analyze(paths: Iterable[Union[str, Path]]):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      per_sensor_index_counts: {sensor: Counter({index: count, ...}), ...}\n",
    "      per_sensor_raw_counts:   {sensor: Counter({rawType: count, ...}), ...}\n",
    "      missing_counts:          Counter({sensor: num_events_with_no_data, ...})\n",
    "      missing_event_ids:       {sensor: set(event_ids_with_no_data)}\n",
    "      combo_counts:            Counter({combo_label: num_events})\n",
    "    \"\"\"\n",
    "    per_sensor_index_counts = defaultdict(Counter)\n",
    "    per_sensor_raw_counts = defaultdict(Counter)\n",
    "\n",
    "    # Track whether each (event_id, sensor) has ANY raster at all\n",
    "    has_data = defaultdict(lambda: {s: False for s in SENSORS})\n",
    "    all_event_ids = set()\n",
    "\n",
    "    for p in paths:\n",
    "        p = Path(p)\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "\n",
    "        sensor = get_sensor(p)\n",
    "        event_id = get_event_id(p)\n",
    "        all_event_ids.add(event_id)\n",
    "\n",
    "        if sensor not in SENSORS:\n",
    "            continue\n",
    "\n",
    "        if is_raster(p):\n",
    "            # presence flag\n",
    "            has_data[event_id][sensor] = True\n",
    "\n",
    "            # indices per sensor\n",
    "            idx = detect_index(p.name)\n",
    "            if idx:\n",
    "                per_sensor_index_counts[sensor][idx] += 1\n",
    "\n",
    "            # raw/product type per sensor\n",
    "            raw_type = detect_raw_type(sensor, p.name)\n",
    "            if raw_type:\n",
    "                per_sensor_raw_counts[sensor][raw_type] += 1\n",
    "\n",
    "    # Compute missing events per sensor\n",
    "    missing_event_ids = {s: set() for s in SENSORS}\n",
    "    for ev in all_event_ids:\n",
    "        row = has_data.get(ev, {s: False for s in SENSORS})\n",
    "        for s in SENSORS:\n",
    "            if not row.get(s, False):\n",
    "                missing_event_ids[s].add(ev)\n",
    "\n",
    "    missing_counts = Counter({s: len(missing_event_ids[s]) for s in SENSORS})\n",
    "\n",
    "    # Build combination labels per event\n",
    "    combo_counts = Counter()\n",
    "    for ev in all_event_ids:\n",
    "        present = [s for s in SENSORS if has_data[ev].get(s, False)]\n",
    "        if len(present) == 0:\n",
    "            combo_label = \"none\"\n",
    "        elif len(present) == 1:\n",
    "            # \"only s2\", etc.\n",
    "            pl = SENSOR_ALIASES.get(present[0], present[0])\n",
    "            combo_label = f\"only {pl}\"\n",
    "        else:\n",
    "            # \"s1+s2\", \"s2+ls\", etc. (use aliases, keep SENSORS order)\n",
    "            parts = [SENSOR_ALIASES.get(s, s) for s in present]\n",
    "            combo_label = \"+\".join(parts)\n",
    "        combo_counts[combo_label] += 1\n",
    "\n",
    "    return (per_sensor_index_counts,\n",
    "            per_sensor_raw_counts,\n",
    "            missing_counts,\n",
    "            missing_event_ids,\n",
    "            combo_counts)\n",
    "\n",
    "# ------------------- Pretty printing ----------------\n",
    "def print_summary(per_sensor_index_counts,\n",
    "                  per_sensor_raw_counts,\n",
    "                  missing_counts,\n",
    "                  missing_event_ids,\n",
    "                  combo_counts,\n",
    "                  show_missing_lists=False):\n",
    "    print(\"\\n=== INDEX COUNTS PER SENSOR ===\")\n",
    "    for sensor in SENSORS:\n",
    "        cnt = per_sensor_index_counts.get(sensor, Counter())\n",
    "        print(f\"\\n[{sensor}]\")\n",
    "        if cnt:\n",
    "            for k, v in cnt.most_common():\n",
    "                print(f\"  {k:12s} {v:6d}\")\n",
    "        else:\n",
    "            print(\"  (no index rasters found)\")\n",
    "\n",
    "    print(\"\\n=== RAW/PRODUCT TYPE COUNTS PER SENSOR ===\")\n",
    "    for sensor in SENSORS:\n",
    "        cnt = per_sensor_raw_counts.get(sensor, Counter())\n",
    "        print(f\"\\n[{sensor}]\")\n",
    "        if cnt:\n",
    "            for k, v in cnt.most_common():\n",
    "                print(f\"  {k:12s} {v:6d}\")\n",
    "        else:\n",
    "            print(\"  (no raw/product-type rasters found)\")\n",
    "\n",
    "    print(\"\\n=== EVENTS WITH NO DATA BY SENSOR ===\")\n",
    "    for sensor in SENSORS:\n",
    "        print(f\"  {sensor:10s}: {missing_counts[sensor]:6d} events with no rasters\")\n",
    "\n",
    "    print(\"\\n=== SENSOR PRESENCE COMBINATIONS (per event) ===\")\n",
    "    for label, n in combo_counts.most_common():\n",
    "        print(f\"  {label:15s} {n:6d}\")\n",
    "\n",
    "    if show_missing_lists:\n",
    "        print(\"\\n=== LIST OF EVENT IDS WITH NO DATA (per sensor) ===\")\n",
    "        for sensor in SENSORS:\n",
    "            ids = sorted(missing_event_ids[sensor])\n",
    "            print(f\"\\n[{sensor}] ({len(ids)}):\")\n",
    "            if ids:\n",
    "                print(\", \".join(ids))\n",
    "            else:\n",
    "                print(\"  (none)\")\n",
    "\n",
    "# ------------------- Example usage ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Option A: Walk your on-disk tree under ./data\n",
    "    results = analyze(iter_paths(BASE_DIR))\n",
    "    print_summary(*results, show_missing_lists=False)\n",
    "\n",
    "    # Option B: Use prebuilt lists instead of walking the FS (uncomment):\n",
    "    # sample_all = s2_list + s1_list + landsat_list + cbers_list\n",
    "    # results = analyze(sample_all)\n",
    "    # print_summary(*results, show_missing_lists=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d156da-28b2-45c1-8792-f4d81f3ebcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_with = sorted([k for k in glob.glob(\"data/*/sentinel2/*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k])\n",
    "len(s2_band_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f817c3-9119-4aa3-a6f8-997349d78593",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_band_paths = sorted([k for k in glob.glob(\"data/*/sentinel2/*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k])\n",
    "len(s2_band_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2368c-69c8-4706-a799-be5c1a361ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfbb62-0ef8-4e03-bc82-15ecd40fda99",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique([k.split(\"/\")[1] for k in s2_band_paths if \"_S2-16D_V2_\" in k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41a0d2-fd57-44dc-a81e-38dd62a05687",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([k for k in s2_band_paths if \"_S2-16D_V2_\" in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4dcf84-c6d5-4782-8031-538dbd396519",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique([k.split(\"/\")[1] for k in s2_band_paths if \"L2A\" in k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c988984-1b43-4f6e-800b-2eb124322ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([k for k in s2_band_paths if \"L2A\" in k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091501f-b2f2-4ac1-a9a6-87fbb916d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_band_paths = sorted([k for k in glob.glob(\"data/*/sentinel2/*.tif\") if \"_ndvi\" in k])\n",
    "len(s2_band_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd0a89-c36d-4d79-98d1-8e921ff51a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = rasterio.open(s2_band_paths[rand_int]).read()\n",
    "img_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f5ad7-a1d6-42ce-94a3-1fd8dfb503f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ae251-9bd6-42ad-b779-2db8b562a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e016d-4ca4-4116-9af5-f765d62fa65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "red_to_green = LinearSegmentedColormap.from_list(\"RedGreen\", [\"red\", \"green\"])\n",
    "\n",
    "for k in range(10):\n",
    "    rand_int = np.random.randint(len(s2_band_paths))\n",
    "    ndvi = rasterio.open(s2_band_paths[rand_int]).read(1)\n",
    "    print(ndvi.min(), ndvi.max())\n",
    "    # img_orig = tifffile.imread(s2_band_paths[rand_int])\n",
    "    # img = visualize_s2_concat_bands_path(s2_band_paths[rand_int])\n",
    "    ending = s2_band_paths[rand_int].split(\"/\")[-1]\n",
    "\n",
    "    f, ax = plt.subplots(1, 2, figsize=(30, 10))\n",
    "    ax[0].imshow(ndvi, vmin=-2000, vmax=6000, cmap=red_to_green)\n",
    "    ax[0].set_title(f\"{ending[:30]}\", fontsize=15)\n",
    "    # ax[0].set_title(f\"{ending[:30]}: {img_orig.shape}\", fontsize=15)\n",
    "    # pred = ((preds[i].astype(np.float32) / 255.0) > threshold) * 1\n",
    "    ax[1].imshow(ndvi, vmin=-2000, vmax=6000, cmap=red_to_green)\n",
    "    # axarr[1].imshow(np.ma.masked_where(pred == 0, pred), cmap=\"spring\", alpha=alpha)\n",
    "    # title_string = f\"FPs: {fps[i]:.0f} = {100 * fps[i] / fp_sum:.1f}%, FNs: {fns[i]:.0f} = {100 * fns[i] / fn_sum:.1f}%, TPs: {tps[i]:.0f}\"\n",
    "    # axarr[1].set_title(f\"(Pred) {title_string}\", fontsize=fontsize)\n",
    "    \n",
    "    # label = tifffile.imread(GT_paths[i])\n",
    "    # nan_mask = label == 255\n",
    "    # label = ((label >= 2) & (label <= 4)).astype(np.uint8)\n",
    "    # label[nan_mask] = 0\n",
    "    # ax[1].imshow(img)\n",
    "    # axarr[2].imshow(np.ma.masked_where(label != 1, label), cmap=\"spring\", alpha=alpha)\n",
    "    ax[1].set_title(f\"image with GT mask\", fontsize=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4c18e-fec3-4215-bb96-ab9b5789bcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
