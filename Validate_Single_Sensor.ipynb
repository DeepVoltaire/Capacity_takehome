{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47382a04-3378-458b-875c-4ce62a6e4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031383c-6318-4d2e-86f9-6ace15e99fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import tifffile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import shape\n",
    "import glob\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import json\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "red_to_green = LinearSegmentedColormap.from_list(\"RedGreen\", [\"red\", \"green\"])\n",
    "\n",
    "from src.train import train\n",
    "from src.hyperparams import HyperParams, open_from_yaml\n",
    "from src.data import *\n",
    "from src.validate import return_metrics_all_folds, visualize_single_model, cross_validation, visualize_s2_concat_bands_path\n",
    "from src.visualize import visualize_s2_concat_bands_path, visualize_s1_path, scale_img, visualize_ls_concat_bands_path, visualize_cb_mux_path, visualize_cb_wpm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf1f069-60c9-4254-9fd6-b2833a378e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob.glob(\"trained_models/ExpS2*/*/*/best_metric*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0222c-a0a7-46c2-bb09-447cd6aadb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob.glob(\"trained_models/ExpS1*/*/*/best_metric*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f2051-5469-44da-b857-2438fb8bdd4a",
   "metadata": {},
   "source": [
    "# S2 single sensor, single before/after image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04e0e7-427b-4fb0-8e45-aa98546de5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob.glob(\"trained_models/ExpS2*/*/*/best_metric*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf4ffa-68a1-4b42-a86b-42abeae16ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_list = []\n",
    "hps = HyperParams(**open_from_yaml(\"trained_models/ExpS2_single_2-0\"))\n",
    "hps_list.append(hps)\n",
    "df = pd.read_pickle(hps.df_path)\n",
    "\n",
    "pred_name = \"_\".join([hps_.name for hps_ in hps_list])\n",
    "print(pred_name)\n",
    "# threshold = 0.5 #0.8 #0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7252f-308e-4114-bfb8-9cc1b03b4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "also_save_preds = True\n",
    "threshold = 0.5\n",
    "fold_nbs = [0, 1, 2, 3, 4] #[0, 1] #, 2, 3, 4]#, 1, 2, 3, 4] #[4] \n",
    "\n",
    "subset = \"val_all_folds\"\n",
    "export = return_metrics_all_folds(hps_list, threshold=threshold, on_gpu=True, output_spatial_size=(400, 400), also_save_preds=also_save_preds,\n",
    "                                  save_path=f\"/data/C2S_CNN/predictions/{pred_name}_{subset}.bc\", fold_nbs=fold_nbs)\n",
    "# export_path = f\"data/metrics_{pred_name}_{subset}.npy\"\n",
    "# np.save(export_path, export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b642cf4-c311-4c74-b76d-a111276c72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, losses, tps, fps, fns = export\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a2f5f1-4cf5-4b84-aa26-98ef29994ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths_before, img_paths_after, GT_paths = [], [], []\n",
    "hps.only_val = True\n",
    "for fold_nb in fold_nbs:    \n",
    "    hps.fold_nb = fold_nb\n",
    "    val_dataset, val_loader = get_dataloaders(hps=hps)\n",
    "    img_paths_before.extend(val_dataset.img_paths_before)\n",
    "    img_paths_after.extend(val_dataset.img_paths_after)\n",
    "    GT_paths.extend(val_dataset.mask_paths)\n",
    "\n",
    "print(len(img_paths_before), len(img_paths_after), len(GT_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d2171-5f29-43cf-8249-c0538d7f4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_criteria = \"FP+FN\" #\"FP+FN\" #\"FP+FN ratio\" #\"(FP+FN)/TP ratio\" #\"FP+FN\" #\"random\" #\"FP+FN\" #\"random\" \n",
    "\n",
    "looked_at_paths, looked_at_idx = visualize_single_model(\n",
    "    df, tps, fps, fns, [probs], threshold, img_paths_before, img_paths_after, GT_paths, export_how_many=50, skip_how_many=0, alpha=0.4, \n",
    "    selection_criteria=selection_criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa53266-8ef5-4105-8743-5b615dc360e1",
   "metadata": {},
   "source": [
    "# S1 single sensor, single before/after image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7c135-1ddd-442e-82bc-bc2124be3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(glob.glob(\"trained_models/*/*/*/best_metric*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a56b6-5d73-4bbe-82ed-6827d36f81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_list = []\n",
    "hps = HyperParams(**open_from_yaml(\"trained_models/ExpS1_single_2-0\"))\n",
    "hps_list.append(hps)\n",
    "df = pd.read_pickle(hps.df_path)\n",
    "\n",
    "pred_name = \"_\".join([hps_.name for hps_ in hps_list])\n",
    "print(pred_name)\n",
    "# threshold = 0.5 #0.8 #0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd0aee-494a-4b0f-8434-56510ea0d10e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "also_save_preds = True\n",
    "threshold = 0.5\n",
    "fold_nbs = [0, 1, 2, 3, 4]#, 1, 2, 3, 4] #[4] \n",
    "\n",
    "subset = \"val_all_folds\"\n",
    "export = return_metrics_all_folds(hps_list, threshold=threshold, on_gpu=True, output_spatial_size=(400, 400), also_save_preds=also_save_preds,\n",
    "                                  save_path=f\"/data/C2S_CNN/predictions/{pred_name}_{subset}.bc\", fold_nbs=fold_nbs)\n",
    "# export_path = f\"data/metrics_{pred_name}_{subset}.npy\"\n",
    "# np.save(export_path, export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d913c3-e2ee-48b1-b518-f55114312fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, losses, tps, fps, fns = export\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd3a6a-d123-4563-b230-1508929d3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths_before, img_paths_after, GT_paths = [], [], []\n",
    "hps.only_val = True\n",
    "for fold_nb in fold_nbs:    \n",
    "    hps.fold_nb = fold_nb\n",
    "    val_dataset, val_loader = get_dataloaders(hps=hps)\n",
    "    img_paths_before.extend(val_dataset.img_paths_before)\n",
    "    img_paths_after.extend(val_dataset.img_paths_after)\n",
    "    GT_paths.extend(val_dataset.mask_paths)\n",
    "\n",
    "print(len(img_paths_before), len(img_paths_after), len(GT_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c59ed-327c-40ec-a1b0-f71d8db4056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_criteria = \"FP+FN\" #\"FP+FN\" #\"FP+FN ratio\" #\"(FP+FN)/TP ratio\" #\"FP+FN\" #\"random\" #\"FP+FN\" #\"random\" \n",
    "specific_location = 0 #\"Senanga\" #\"Matadi\" #\"South America - Argentina\" #0 #\"Santa Cruz do Sul\" #\"Timbuktu\" #0 #\"Eritrea\" #0\n",
    "\n",
    "looked_at_paths, looked_at_idx = visualize_single_model(\n",
    "    df, tps, fps, fns, [probs], threshold, img_paths_before, img_paths_after, GT_paths, export_how_many=50, skip_how_many=0, alpha=0.5, \n",
    "    selection_criteria=selection_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c9e00-3677-47a1-99bf-ba4bcd70a699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
