{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031383c-6318-4d2e-86f9-6ace15e99fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tifffile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 250)\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import shape\n",
    "import glob\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import json\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "red_to_green = LinearSegmentedColormap.from_list(\"RedGreen\", [\"red\", \"green\"])\n",
    "\n",
    "from src.train import train\n",
    "from src.hyperparams import HyperParams, open_from_yaml\n",
    "from src.data import *\n",
    "from src.visualize import visualize_s2_concat_bands_path, visualize_s1_path, scale_img, visualize_ls_concat_bands_path, visualize_cb_mux_path, visualize_cb_wpm_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122686c3-1bba-40f0-9abb-873d4967c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts_with_data = len(set([k.split(\"/\")[1] for k in glob.glob(f\"data/*/*/*.tif\")]))\n",
    "print(f\"There is any satellite data for {alerts_with_data} alerts\")\n",
    "\n",
    "alerts_with_s1 = len(set([k.split(\"/\")[1] for k in glob.glob(f\"data/*/sentinel1/*.tif\")]))\n",
    "alerts_with_ls = len(set([k.split(\"/\")[1] for k in glob.glob(f\"data/*/landsat/*.tif\")]))\n",
    "alerts_with_mux = len(set([k.split(\"/\")[1] for k in glob.glob(f\"data/*/cbers4a/*MUX*.tif\")]))\n",
    "alerts_with_wpm = len(set([k.split(\"/\")[1] for k in glob.glob(f\"data/*/cbers4a/*WPM*.tif\")]))\n",
    "alerts_with_s2_l2a = len(set([k.split(\"/\")[1] for k in glob.glob(f\"data/*/sentinel2/*L2A*.tif\")]))\n",
    "alerts_with_s2_16d = len(set([k.split(\"/\")[1] for k in glob.glob(f\"data/*/sentinel2/*16D*.tif\")]))\n",
    "alerts_with_s2 = len(set([k.split(\"/\")[1] for k in glob.glob(f\"data/*/sentinel2/*L2A*.tif\")] + [k.split(\"/\")[1] for k in glob.glob(f\"data/*/sentinel2/*16D*.tif\")]))\n",
    "\n",
    "print(f\"There is any S2 data for {alerts_with_s2} alerts\")\n",
    "print(f\"There is S2 L2A data for {alerts_with_s2_l2a} alerts\")\n",
    "print(f\"There is S2 16D data for {alerts_with_s2_16d} alerts\")\n",
    "print(f\"There is LS data for     {alerts_with_ls} alerts\")\n",
    "print(f\"There is S1 data for     {alerts_with_s1} alerts\")\n",
    "print(f\"There is MUX data for    {alerts_with_mux} alerts\")\n",
    "print(f\"There is WPM data for    {alerts_with_wpm} alerts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f2051-5469-44da-b857-2438fb8bdd4a",
   "metadata": {},
   "source": [
    "# S2 single sensor, single before/after image\n",
    "- Now that I have managed to align L2A and 16D products for Sentinel2, I can train a model on their combined data.\n",
    "- For 100 alerts, we have some data for 82 of them. From those 82, we have S2 L2A data for 68 of them and S2 16D data for 63. Using them together, we have data for 77 alerts.\n",
    "- As this is still low data, we will\n",
    "  - use pretrained encoder\n",
    "  - create a cross validation dataset with 5 folds to get more robust performance on the full dataset\n",
    "  - create one deforestation example per alert by using the first \"before\" image and the last \"after\" image with respect to the deforestation event. With good labels, we would like to change this by using \"before\" and \"after images as close as possible to each other to train the model to detect deforestation events from one image to the next. But here, as our label timings are really not that good looking, I found that the before and after images right next to each other do not feature the deforestation changes.\n",
    "  - create negative examples of deforestation by sampling inside the \"before\" images and adding an empty deforestation mask. Same for within the \"after\" images. This is important as in earlier experiments, I found the model to learn to predict always deforestation in the middle of the scene as this was a good baseline if every example features deforestation and is also roughly centered on it. Random cropping also helps here as it moves the deforestation position to the sides of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3ae77-1192-43da-bf7f-30ee9bef3476",
   "metadata": {},
   "source": [
    "## Create cross validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c5c82-c50c-4292-9d11-ecdbf75ec1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(\"data/mapbiomas_alerts.geojson\")\n",
    "events_sorted_by_area = df.sort_values(\"areaHa\", ascending=False)[\"alertCode\"].tolist()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e98212-b27f-4a21-b5db-5b22a0f8fcd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths_before_, paths_after_ = [], []\n",
    "clouds_nodata_before_, clouds_nodata_after_ = [], []\n",
    "label_paths, deforest_pxs = [], []\n",
    "s2_valid_data_events = []\n",
    "seed = 11219\n",
    "seed_count = 0\n",
    "for event_id in events_sorted_by_area[:]:\n",
    "    s2_l2a_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel2/*L2A*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k and not \"compressed\" in k])\n",
    "    s2_16d_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel2/*16D*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k and not \"compressed\" in k])\n",
    "    s2_paths = s2_l2a_paths + s2_16d_paths\n",
    "    if len(s2_paths) == 0:\n",
    "        continue\n",
    "    mask_path = glob.glob(f\"data/{event_id}/*_mask.tif\")[0]\n",
    "    mask_date = mask_path.split(\"/\")[-1].split('_')[1]\n",
    "    mask_date_str = f\"{mask_date[:4]}-{mask_date[4:6]}-{mask_date[6:8]}\"\n",
    "    mask_date = datetime.strptime(mask_date, \"%Y%m%d\")\n",
    "    # print(mask_date)\n",
    "    \n",
    "    date = mask_path.split(\"/\")[-1].split('_')[1]\n",
    "    # Sort by the date right before the .tif\n",
    "    paths = sorted(s2_paths, key=lambda p: datetime.strptime(p.split('_')[-1].split('.')[0], \"%Y%m%d\"))\n",
    "    \n",
    "    paths_after, paths_before = [], []\n",
    "    clouds_nodata_after, clouds_nodata_before = [], []\n",
    "    for path in paths:\n",
    "        img_orig = tifffile.imread(path)\n",
    "        if \"L2A\" in path:\n",
    "            scl = img_orig[:, :, -2].copy()\n",
    "            img_orig = img_orig[:, :, [11, 8, 4]]\n",
    "        else:\n",
    "            scl = img_orig[:, :, -1].copy()\n",
    "            img_orig = img_orig[:, :, [10, 7, 3]]\n",
    "        img_orig = img_orig.astype(np.float32)\n",
    "        if scl.max() > 11:\n",
    "            if scl.max() > 50:\n",
    "                factor = 6\n",
    "            elif scl.max() > 45:\n",
    "                factor = 5\n",
    "            elif scl.max() >= 40:\n",
    "                factor = 4.5\n",
    "            else:\n",
    "                factor = 4\n",
    "            img_orig = (img_orig / factor).round(0)\n",
    "            scl_clean = (scl / factor).round(0).astype('uint8')   # back to 0..11\n",
    "        else:\n",
    "            factor = 1\n",
    "            scl_clean = scl.copy()\n",
    "        img_orig[img_orig == 0] = np.nan\n",
    "        # low values, but all minimum above 1000 ==> Subtract by 1000\n",
    "        if (np.nanmin(img_orig, axis=(0,1)) > 1000).sum() == 3:\n",
    "            img_orig = img_orig - 1000\n",
    "            img_orig[img_orig < 0] = np.nan\n",
    "        \n",
    "        cloudshadowmask = np.isin(scl_clean, [3, 8, 9, 10]).astype(np.uint8)   # clouds + shadows\n",
    "        clouds_perc = 100 * cloudshadowmask.sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "        nodata_perc = 100 * np.isnan(img_orig[:, :, 0]).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "        \n",
    "        date = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "        date_str = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "            \n",
    "        date = datetime.strptime(path.split('_')[-1].split('.')[0], \"%Y%m%d\")\n",
    "        if date > mask_date:\n",
    "            paths_after.append(path)\n",
    "            clouds_nodata_after.append(clouds_perc + nodata_perc)\n",
    "        else:\n",
    "            paths_before.append(path)\n",
    "            clouds_nodata_before.append(clouds_perc + nodata_perc)\n",
    "    print(f\"{event_id}: {len(s2_l2a_paths):2} S2 L2A paths, {len(s2_16d_paths):2} 16D paths, {len(paths_before):2} before, {len(paths_after):2} after, ({mask_date})\")\n",
    "    if len(clouds_nodata_before) > 0 and len(clouds_nodata_after) > 0:\n",
    "        print(f\" --> min nodata/clouds before: {min(clouds_nodata_before):5.1f}%, after: {min(clouds_nodata_after):5.1f}%\")\n",
    "    if len(paths_before) > 0 and len(paths_after) > 0:\n",
    "        label_path = glob.glob(f\"data/{event_id}/*_mask.tif\")[0]\n",
    "        label_paths.append(label_path)\n",
    "        label = tifffile.imread(label_path)\n",
    "        deforest_pxs.append((label == 255).sum())\n",
    "        \n",
    "        s2_valid_data_events.append(event_id)\n",
    "        paths_after_.append(paths_after)\n",
    "        clouds_nodata_after_.append(clouds_nodata_after)\n",
    "        paths_before_.append(paths_before)\n",
    "        clouds_nodata_before_.append(clouds_nodata_before)\n",
    "\n",
    "    if len(paths_before) > 2: # Create a new no deforestation example from the before images\n",
    "        before_indices = np.arange(len(paths_before))\n",
    "        np.random.seed(seed + seed_count)\n",
    "        seed_count += 1\n",
    "        np.random.shuffle(before_indices)\n",
    "        sorted_indices_new_example = sorted(before_indices[:2])\n",
    "        sorted_paths_new_example = [path for k, path in enumerate(paths_before) if k in sorted_indices_new_example]\n",
    "        \n",
    "        s2_valid_data_events.append(f\"{event_id}_no_change_before\")\n",
    "        label_paths.append(\"empty\")\n",
    "        deforest_pxs.append(0)\n",
    "        paths_after_.append([sorted_paths_new_example[1]])\n",
    "        clouds_nodata_after_.append([clouds_nodata_before[sorted_indices_new_example[1]]])\n",
    "        paths_before_.append([sorted_paths_new_example[0]])\n",
    "        clouds_nodata_before_.append([clouds_nodata_before[sorted_indices_new_example[0]]])\n",
    "        \n",
    "    if len(paths_after) > 2: # Create a new no deforestation example from the before images\n",
    "        after_indices = np.arange(len(paths_after))\n",
    "        np.random.seed(seed + seed_count)\n",
    "        seed_count += 1\n",
    "        np.random.shuffle(after_indices)\n",
    "        sorted_indices_new_example = sorted(after_indices[:2])\n",
    "        sorted_paths_new_example = [path for k, path in enumerate(paths_after) if k in sorted_indices_new_example]\n",
    "        \n",
    "        s2_valid_data_events.append(f\"{event_id}_no_change_after\")\n",
    "        label_paths.append(\"empty\")\n",
    "        deforest_pxs.append(0)\n",
    "        paths_after_.append([sorted_paths_new_example[1]])\n",
    "        clouds_nodata_after_.append([clouds_nodata_after[sorted_indices_new_example[1]]])\n",
    "        paths_before_.append([sorted_paths_new_example[0]])\n",
    "        clouds_nodata_before_.append([clouds_nodata_after[sorted_indices_new_example[0]]])\n",
    "len(s2_valid_data_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e464b-74d2-41c3-ae73-b4e150ca2896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"event_id\": s2_valid_data_events, \n",
    "                   \"deforest_pxs\": deforest_pxs, \"label_path\": label_paths,\n",
    "                   \"paths_before\": paths_before_, \"clouds_nodata_before\": clouds_nodata_before_,\n",
    "                   \"paths_after\": paths_after_, \"clouds_nodata_after\": clouds_nodata_after_})\n",
    "df.to_pickle(\"catalogues/2025_08_19_s2_rawdata.pkl\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d4a43-1056-490a-a074-78f93c34b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"catalogues/2025_08_19_s2_rawdata.pkl\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff2c89-0aba-4c07-a405-c3214802da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_before_path(row):\n",
    "    # FURTHEST AWAY FROM DEFORESTATON DATE\n",
    "    clouds_nodata_before = row[\"clouds_nodata_before\"]\n",
    "    paths_before = row[\"paths_before\"]\n",
    "    \n",
    "    # # CLOSEST TO DEFORESTATON DATE\n",
    "    # clouds_nodata_before = row[\"clouds_nodata_before\"][::-1]\n",
    "    # paths_before = row[\"paths_before\"][::-1]\n",
    "\n",
    "    # Take the closest deforestation date with clouds < 3%\n",
    "    for clouds_nodata, path in zip(clouds_nodata_before, paths_before):\n",
    "        if clouds_nodata < 3:\n",
    "            return path, clouds_nodata\n",
    "    # Take the closest deforestation date with clouds < 10%\n",
    "    for clouds_nodata, path in zip(clouds_nodata_before, paths_before):\n",
    "        if clouds_nodata < 10:\n",
    "            return path, clouds_nodata\n",
    "    # Take the closest deforestation date with clouds < 30%\n",
    "    for clouds_nodata, path in zip(clouds_nodata_before, paths_before):\n",
    "        if clouds_nodata < 30:\n",
    "            return path, clouds_nodata\n",
    "    # Take the closest deforestation date with clouds < 100%\n",
    "    for clouds_nodata, path in zip(clouds_nodata_before, paths_before):\n",
    "        if clouds_nodata < 100:\n",
    "            return path, clouds_nodata\n",
    "    # Else return the closest path\n",
    "    return paths_before[0], clouds_nodata_before[0]\n",
    "\n",
    "def best_after_path(row):\n",
    "    # FURTHEST AWAY FROM DEFORESTATON DATE\n",
    "    clouds_nodata_after = row[\"clouds_nodata_after\"][::-1]\n",
    "    paths_after = row[\"paths_after\"][::-1]\n",
    "    \n",
    "    # # CLOSEST TO DEFORESTATON DATE\n",
    "    # clouds_nodata_after = row[\"clouds_nodata_after\"]\n",
    "    # paths_after = row[\"paths_after\"]\n",
    "\n",
    "    # Take the closest deforestation date with clouds < 3%\n",
    "    for clouds_nodata, path in zip(clouds_nodata_after, paths_after):\n",
    "        if clouds_nodata < 3:\n",
    "            return path, clouds_nodata\n",
    "    # Take the closest deforestation date with clouds < 10%\n",
    "    for clouds_nodata, path in zip(clouds_nodata_after, paths_after):\n",
    "        if clouds_nodata < 10:\n",
    "            return path, clouds_nodata\n",
    "    # Take the closest deforestation  date with clouds < 30%\n",
    "    for clouds_nodata, path in zip(clouds_nodata_after, paths_after):\n",
    "        if clouds_nodata < 30:\n",
    "            return path, clouds_nodata\n",
    "    # Take the closest deforestation date with clouds < 100%\n",
    "    for clouds_nodata, path in zip(clouds_nodata_after, paths_after):\n",
    "        if clouds_nodata < 100:\n",
    "            return path, clouds_nodata\n",
    "    # Else return the closest path\n",
    "    return paths_after[0], clouds_nodata_after[0]\n",
    "    \n",
    "df[\"path_best_before\"] = df[[\"paths_before\", \"clouds_nodata_before\"]].apply(lambda row: best_before_path(row)[0], axis=1)\n",
    "df[\"path_best_after\"] = df[[\"paths_after\", \"clouds_nodata_after\"]].apply(lambda row: best_after_path(row)[0], axis=1)\n",
    "\n",
    "df[\"clouds_nodata_best_before\"] = df[[\"paths_before\", \"clouds_nodata_before\"]].apply(lambda row: best_before_path(row)[1], axis=1)\n",
    "df[\"clouds_nodata_best_after\"] = df[[\"paths_after\", \"clouds_nodata_after\"]].apply(lambda row: best_after_path(row)[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ba6cc-70f0-49fb-97d7-15b424121342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clouds_nodata_best_before\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071c73f-9fc9-46b5-91f9-6224bfe361e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clouds_nodata_best_after\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb7cec-f4c4-470c-9df0-5fb08b1b1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle(\"catalogues/2025_08_19_s2_l2a_16d.pkl\")\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22a7881-22b7-4271-ad03-7afcba2cea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[(df[\"label_path\"]==\"empty\") | ((df[\"clouds_nodata_best_before\"] < 30) & (df[\"clouds_nodata_best_after\"] < 30))]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe615dfe-b37b-46b2-b50c-bfb83d7a1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e59e34-b311-4ae6-ac45-8dccbf591745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"event_id\"] = df[\"event_id\"].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee7b0a-2ed8-4f9e-bddc-82ca886f8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"event_id_for_folds\"] = df[\"event_id\"].apply(lambda x: x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4335f65-798a-4aab-9806-3f9369e02429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"event_id_for_folds\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0d9e4-9f5b-4a47-9051-95216877d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assign_groups_to_folds(df, group_col, target_col, n_splits, seed):\n",
    "    \"\"\"Greedy randomized bin packing: assign whole groups to the fold with the smallest total.\"\"\"\n",
    "    tmp = df[[group_col, target_col]].copy()\n",
    "    tmp[group_col] = tmp[group_col].astype(object).fillna(\"__MISSING_GROUP__\")\n",
    "    tmp[target_col] = pd.to_numeric(tmp[target_col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    grp_sum = tmp.groupby(group_col, dropna=False)[target_col].sum()\n",
    "    groups = grp_sum.index.to_numpy()\n",
    "    weights = grp_sum.to_numpy(dtype=float)\n",
    "\n",
    "    if len(groups) < n_splits:\n",
    "        raise ValueError(f\"Need at least {n_splits} distinct groups in {group_col}.\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Sort groups by descending weight with tiny random jitter to randomize ties.\n",
    "    jitter = rng.random(len(weights)) * 1e-9\n",
    "    order = np.argsort(-(weights + jitter))\n",
    "\n",
    "    fold_sums = np.zeros(n_splits, dtype=float)\n",
    "    assignment = {}\n",
    "\n",
    "    # Ensure every fold gets at least one (the n_splits heaviest go one-per-fold).\n",
    "    for i, idx in enumerate(order[:n_splits]):\n",
    "        assignment[groups[idx]] = i\n",
    "        fold_sums[i] += weights[idx]\n",
    "\n",
    "    # Assign the rest to the currently lightest fold (tie-break randomly).\n",
    "    for idx in order[n_splits:]:\n",
    "        min_sum = fold_sums.min()\n",
    "        candidates = np.flatnonzero(fold_sums == min_sum)\n",
    "        fold = int(rng.choice(candidates))\n",
    "        assignment[groups[idx]] = fold\n",
    "        fold_sums[fold] += weights[idx]\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"_grp_\"] = out[group_col].astype(object).fillna(\"__MISSING_GROUP__\")\n",
    "    out[\"fold\"] = out[\"_grp_\"].map(assignment).astype(int)\n",
    "    out.drop(columns=\"_grp_\", inplace=True)\n",
    "\n",
    "    # Safety: each group in exactly one fold\n",
    "    assert out.groupby(group_col)[\"fold\"].nunique().max() == 1\n",
    "\n",
    "    return out\n",
    "\n",
    "def add_balanced_group_folds_until(\n",
    "    df: pd.DataFrame,\n",
    "    group_col: str = \"event_id_for_folds\",\n",
    "    target_col: str = \"deforest_pxs\",\n",
    "    n_splits: int = 5,\n",
    "    std_threshold: float = 1250.0,\n",
    "    start_seed: int = 0,\n",
    "    max_seeds: int = 10_000,\n",
    "    return_best_if_not_met: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Try seeds start_seed .. start_seed+max_seeds-1.\n",
    "    Return the first split with std < std_threshold.\n",
    "    If none meets the threshold and return_best_if_not_met is True, return the best found.\n",
    "    \"\"\"\n",
    "    best = {\"std\": float(\"inf\"), \"seed\": None, \"df\": None}\n",
    "\n",
    "    for seed in range(start_seed, start_seed + max_seeds):\n",
    "        out = _assign_groups_to_folds(df, group_col, target_col, n_splits, seed)\n",
    "        std_counts = out.groupby(\"fold\")[target_col].sum().std()  # sample std (ddof=1), same as your snippet\n",
    "\n",
    "        # Track best\n",
    "        if std_counts < best[\"std\"]:\n",
    "            best = {\"std\": float(std_counts), \"seed\": seed, \"df\": out}\n",
    "\n",
    "        if std_counts < std_threshold:\n",
    "            out.attrs[\"fold_seed\"] = seed\n",
    "            out.attrs[\"fold_std\"] = float(std_counts)\n",
    "            return out  # success\n",
    "\n",
    "    # No seed met the threshold\n",
    "    if return_best_if_not_met and best[\"df\"] is not None:\n",
    "        out = best[\"df\"]\n",
    "        out.attrs[\"fold_seed\"] = best[\"seed\"]\n",
    "        out.attrs[\"fold_std\"] = best[\"std\"]\n",
    "        print(\n",
    "            f\"Warning: no seed achieved std<{std_threshold}. \"\n",
    "            f\"Best std={best['std']:.3f} at seed={best['seed']}.\"\n",
    "        )\n",
    "        return out\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"No seed in range [{start_seed}, {start_seed+max_seeds-1}] achieved std<{std_threshold}.\"\n",
    "    )\n",
    "\n",
    "df = add_balanced_group_folds_until(\n",
    "    df,\n",
    "    group_col=\"event_id_for_folds\",\n",
    "    target_col=\"deforest_pxs\",\n",
    "    n_splits=5,\n",
    "    std_threshold=1250,\n",
    "    start_seed=0,\n",
    "    max_seeds=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e8141-43be-4865-8aec-51096c058b89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.attrs[\"fold_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b832b-0659-4369-b479-26fd8883632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"fold\")[\"deforest_pxs\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d763994a-c1fd-4765-afe4-752d86ea2a44",
   "metadata": {},
   "source": [
    "To speed up data loading during training, it helps to save the tifs uncompressed.\n",
    "- Even faster would be to do most preprocessing before, e.g. loading before/after images, eventual resizing, dropping of bands, normalizing, subtracting offsets, ... and in the dataloader only loading in the final array and doing augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a4a62-b8bf-4727-8f17-f70171882e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    output_path = row[\"path_best_before\"].replace(\".tif\", \"_uncompressed.tif\")\n",
    "    if not os.path.exists(output_path):\n",
    "        with rasterio.open(row[\"path_best_before\"]) as src:\n",
    "            profile = src.profile\n",
    "            profile[\"compress\"] = None\n",
    "            with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "                dst.write(src.read())\n",
    "\n",
    "    output_path = row[\"path_best_after\"].replace(\".tif\", \"_uncompressed.tif\")\n",
    "    if not os.path.exists(output_path):\n",
    "        with rasterio.open(row[\"path_best_after\"]) as src:\n",
    "            profile = src.profile\n",
    "            profile[\"compress\"] = None\n",
    "            with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "                dst.write(src.read())\n",
    "\n",
    "df[\"path_best_before\"] = df[\"path_best_before\"].apply(lambda x: x.replace(\".tif\", \"_uncompressed.tif\"))\n",
    "df[\"path_best_after\"] = df[\"path_best_after\"].apply(lambda x: x.replace(\".tif\", \"_uncompressed.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661db84-7618-4be8-b266-530903a9f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"event_id\", \"deforest_pxs\", \"path_best_before\", \"path_best_after\"]].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7422c6-cdce-4c60-bd96-c92182a0859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"catalogues\", exist_ok=True)\n",
    "df.to_pickle(\"catalogues/2025_08_19_s2_l2a_16d.pkl\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4195f91-a82b-4519-bba4-99617f91e3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"fold\")[\"deforest_pxs\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8460766b-4d40-4d34-a0d7-641bd4092854",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8ed9c-fa99-4bce-b622-dcf4b7a35de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_nb = \"S2_l2a_16d_1-2\"\n",
    "# path = \"catalogues/2025_08_19_s2_single.pkl\"\n",
    "path = \"catalogues/2025_08_19_s2_l2a_16d.pkl\"\n",
    "hps_dict = {\n",
    "    ############\n",
    "    # Data\n",
    "    ############\n",
    "    \"df_path\": path,\n",
    "\n",
    "    ############\n",
    "    # Training\n",
    "    ############\n",
    "\n",
    "    ## Experiment Setup\n",
    "    \"name\": f\"Exp_{exp_nb}\",\n",
    "\n",
    "    ## Model\n",
    "    \"num_classes\": 1,\n",
    "    \"input_channel\": 13,\n",
    "    \"backbone\": \"timm_efficientnet_b1\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"model\": \"unetplusplus\",\n",
    "\n",
    "    # Training Setup\n",
    "    \"print_freq\": 500,\n",
    "    \"use_fp16\": 0,\n",
    "    \"patience\": 8,\n",
    "    \"epoch_start_scheduler\": 10,\n",
    "\n",
    "    # Optimizer\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.0,\n",
    "\n",
    "    ## Data Augmentation on CPU\n",
    "    \"train_crop_size\": 256 + 32 + 32,\n",
    "    \"train_batch_size\": 16, #32\n",
    "    \"da_brightness_magnitude\": 0.0,\n",
    "    \"da_contrast_magnitude\": 0.0,\n",
    "\n",
    "    # Data Augmentation on GPU\n",
    "    \"gpu_da_params\": [0.25],\n",
    "    \n",
    "    ### Loss, Metric\n",
    "    \"alpha\": 0.25,\n",
    "           }\n",
    "\n",
    "for fold_nb in range(0, 5):\n",
    "    hps = HyperParams(**hps_dict)\n",
    "    hps.fold_nb = fold_nb\n",
    "    num_batches = 250 // (hps.train_batch_size * torch.cuda.device_count())\n",
    "    # num_batches = 10\n",
    "    hps.num_batches = num_batches\n",
    "    train_dataset, train_loader, val_dataset, val_loader = get_dataloaders(hps)\n",
    "    # continue\n",
    "\n",
    "    best_metric, best_metric_epoch = train(hps, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0774cf-a3a8-4dfb-aae4-9e0a92386ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_nb = \"S2_l2a_16d_1-1\"\n",
    "# path = \"catalogues/2025_08_19_s2_single.pkl\"\n",
    "path = \"catalogues/2025_08_19_s2_l2a_16d.pkl\"\n",
    "hps_dict = {\n",
    "    ############\n",
    "    # Data\n",
    "    ############\n",
    "    \"df_path\": path,\n",
    "\n",
    "    ############\n",
    "    # Training\n",
    "    ############\n",
    "\n",
    "    ## Experiment Setup\n",
    "    \"name\": f\"Exp_{exp_nb}\",\n",
    "\n",
    "    ## Model\n",
    "    \"num_classes\": 1,\n",
    "    \"input_channel\": 13,\n",
    "    \"backbone\": \"timm_efficientnet_b1\",\n",
    "    \"pretrained\": \"imagenet\",\n",
    "    \"model\": \"unetplusplus\",\n",
    "\n",
    "    # Training Setup\n",
    "    \"print_freq\": 500,\n",
    "    \"use_fp16\": 0,\n",
    "    \"patience\": 8,\n",
    "    \"epoch_start_scheduler\": 10,\n",
    "\n",
    "    # Optimizer\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.0,\n",
    "\n",
    "    ## Data Augmentation on CPU\n",
    "    \"train_crop_size\": 256 + 32 + 32,\n",
    "    \"train_batch_size\": 16, #32\n",
    "    \"cutmix_alpha\": 0,\n",
    "    \"da_brightness_magnitude\": 0.0,\n",
    "    \"da_contrast_magnitude\": 0.0,\n",
    "\n",
    "    # Data Augmentation on GPU\n",
    "    \"gpu_da_params\": [0.25],\n",
    "    \n",
    "    ### Loss, Metric\n",
    "    \"alpha\": 0.25,\n",
    "           }\n",
    "\n",
    "for fold_nb in range(0, 5):\n",
    "    hps = HyperParams(**hps_dict)\n",
    "    hps.fold_nb = fold_nb\n",
    "    num_batches = 250 // (hps.train_batch_size * torch.cuda.device_count())\n",
    "    hps.num_batches = num_batches\n",
    "    train_dataset, train_loader, val_dataset, val_loader = get_dataloaders(hps)\n",
    "\n",
    "    best_metric, best_metric_epoch = train(hps, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53af26-d0ac-4d6b-8786-278bb88174da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"event_id\"]==1387993]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f56b06-fce7-443d-8f67-9e0a2beeb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"event_id\"]==1388078]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64ae4e-eae1-4171-beec-c430cc6317ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.visualize(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697af033-72ee-4d15-bab0-2d05b4b5e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.visualize(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb4d52-5132-4b04-95dd-345025a4b81a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(100):\n",
    "    print(np.unique(train_dataset[k][\"mask\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2a2f0-88dd-435b-aa90-0bba36c8296f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_nb = \"S2_single_1-1\"\n",
    "path = \"catalogues/2025_08_18_s2_single.pkl\"\n",
    "hps_dict = {\n",
    "    ############\n",
    "    # Data\n",
    "    ############\n",
    "    \"df_path\": path,\n",
    "\n",
    "    ############\n",
    "    # Training\n",
    "    ############\n",
    "\n",
    "    ## Experiment Setup\n",
    "    \"name\": f\"Exp{exp_nb}\",\n",
    "\n",
    "    ## Model\n",
    "    \"num_classes\": 1,\n",
    "    \"input_channel\": 15,\n",
    "    \"backbone\": \"timm_efficientnet_b1\",\n",
    "    \"pretrained\": 1,\n",
    "    \"model\": \"unetplusplus\",\n",
    "\n",
    "    # Training Setup\n",
    "#     \"resume\": \"trained_models/Exp7-4/fold_0/2022-02-05_23-13-25/best_metric_18_0.9768.pt\",\n",
    "    \"print_freq\": 500,\n",
    "    \"use_fp16\": 0,\n",
    "    \"patience\": 6, #5,\n",
    "    \"epoch_start_scheduler\": 6,\n",
    "\n",
    "    # Optimizer\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.0,\n",
    "\n",
    "    ## Data Augmentation on CPU\n",
    "    \"train_crop_size\": 400,\n",
    "    \"train_batch_size\": 16, #32\n",
    "    \"cutmix_alpha\": 0,\n",
    "    \"da_brightness_magnitude\": 0.0,\n",
    "    \"da_contrast_magnitude\": 0.0,\n",
    "\n",
    "    # Data Augmentation on GPU\n",
    "    \"gpu_da_params\": [0.25],\n",
    "    \n",
    "    ### Loss, Metric\n",
    "    \"alpha\": 0.5,\n",
    "#     \"loss\": \"lovasz\",\n",
    "           }\n",
    "\n",
    "for fold_nb in range(0, 5):\n",
    "    hps = HyperParams(**hps_dict)\n",
    "    hps.fold_nb = fold_nb\n",
    "    num_batches = 250 // (hps.train_batch_size * torch.cuda.device_count())\n",
    "    # num_batches = 10\n",
    "    hps.num_batches = num_batches\n",
    "    train_dataset, train_loader, val_dataset, val_loader = get_dataloaders(hps)\n",
    "    # continue\n",
    "\n",
    "    best_metric, best_metric_epoch = train(hps, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce6c00-2ffc-4bb6-abb3-fdc6f7aefe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"trained_models/ExpS2_single_1-2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857b6bb-c91d-4754-8c8e-a7a3de228f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_nb = \"S2_single_1-2\"\n",
    "path = \"catalogues/2025_08_18_s2_single.pkl\"\n",
    "hps_dict = {\n",
    "    ############\n",
    "    # Data\n",
    "    ############\n",
    "    \"df_path\": path,\n",
    "\n",
    "    ############\n",
    "    # Training\n",
    "    ############\n",
    "\n",
    "    ## Experiment Setup\n",
    "    \"name\": f\"Exp{exp_nb}\",\n",
    "\n",
    "    ## Model\n",
    "    \"num_classes\": 1,\n",
    "    \"input_channel\": 15,\n",
    "    \"backbone\": \"timm_efficientnet_b1\",\n",
    "    \"pretrained\": 1,\n",
    "    \"model\": \"unetplusplus\",\n",
    "\n",
    "    # Training Setup\n",
    "#     \"resume\": \"trained_models/Exp7-4/fold_0/2022-02-05_23-13-25/best_metric_18_0.9768.pt\",\n",
    "    \"print_freq\": 500,\n",
    "    \"use_fp16\": 0,\n",
    "    \"patience\": 6, #5,\n",
    "    \"epoch_start_scheduler\": 10,\n",
    "\n",
    "    # Optimizer\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.0,\n",
    "\n",
    "    ## Data Augmentation on CPU\n",
    "    \"train_crop_size\": 256 + 32 + 32,\n",
    "    \"train_batch_size\": 16, #32\n",
    "    \"cutmix_alpha\": 0,\n",
    "    \"da_brightness_magnitude\": 0.0,\n",
    "    \"da_contrast_magnitude\": 0.0,\n",
    "\n",
    "    # Data Augmentation on GPU\n",
    "    \"gpu_da_params\": [0.25],\n",
    "    \n",
    "    ### Loss, Metric\n",
    "    \"alpha\": 0.5,\n",
    "#     \"loss\": \"lovasz\",\n",
    "           }\n",
    "\n",
    "for fold_nb in range(0, 5):\n",
    "    hps = HyperParams(**hps_dict)\n",
    "    hps.fold_nb = fold_nb\n",
    "    num_batches = 250 // (hps.train_batch_size * torch.cuda.device_count())\n",
    "    # num_batches = 10\n",
    "    hps.num_batches = num_batches\n",
    "    train_dataset, train_loader, val_dataset, val_loader = get_dataloaders(hps)\n",
    "    # continue\n",
    "\n",
    "    best_metric, best_metric_epoch = train(hps, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd215298-572a-4a3a-b7cb-8619778903ad",
   "metadata": {},
   "source": [
    "## Create cross validation dataset with using the last after image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbe897-377e-410f-9c27-3f7f8aa00dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(\"data/mapbiomas_alerts.geojson\")\n",
    "events_sorted_by_area = df.sort_values(\"areaHa\", ascending=False)[\"alertCode\"].tolist()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0def0e-3fa3-497c-8fc3-3c1062385cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths_before_, paths_after_ = [], []\n",
    "clouds_nodata_before_, clouds_nodata_after_ = [], []\n",
    "s2_valid_data_events = []\n",
    "for event_id in events_sorted_by_area[:]:\n",
    "    s2_paths = sorted([k for k in glob.glob(f\"data/{event_id}/sentinel2/*L2A*.tif\") if not \"ndvi\" in k and not \"ndwi\" in k and not \"uncompressed\" in k])\n",
    "    if len(s2_paths) == 0:\n",
    "        continue\n",
    "    mask_path = glob.glob(f\"data/{event_id}/*_mask.tif\")[0]\n",
    "    mask_date = mask_path.split(\"/\")[-1].split('_')[1]\n",
    "    mask_date_str = f\"{mask_date[:4]}-{mask_date[4:6]}-{mask_date[6:8]}\"\n",
    "    mask_date = datetime.strptime(mask_date, \"%Y%m%d\")\n",
    "    # print(mask_date)\n",
    "    \n",
    "    date = mask_path.split(\"/\")[-1].split('_')[1]\n",
    "    # Sort by the date right before the .tif\n",
    "    paths = sorted(s2_paths, key=lambda p: datetime.strptime(p.split('_')[-1].split('.')[0], \"%Y%m%d\"))\n",
    "    # break\n",
    "    paths_after, paths_before = [], []\n",
    "    clouds_nodata_after, clouds_nodata_before = [], []\n",
    "    for path in paths:\n",
    "        # what_to_do_string = \"SKIP\"\n",
    "        img_orig = tifffile.imread(path)\n",
    "        # img_orig = img_orig.astype(np.float32)\n",
    "        # img_orig = img_orig - 1000\n",
    "        # img_orig[img_orig < 0] = 0\n",
    "        clouds_perc = 100 * (img_orig[:, :, 2] > 3400).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "        nodata_perc = 100 * (img_orig[:, :, 2] <= 1000).sum() / (img_orig.shape[0] * img_orig.shape[1])\n",
    "        date = path.split(\"/\")[-1].split('.')[0].split('_')[-1]\n",
    "        date_str = f\"{date[:4]}-{date[4:6]}-{date[6:8]}\"\n",
    "            \n",
    "        date = datetime.strptime(path.split('_')[-1].split('.')[0], \"%Y%m%d\")\n",
    "        if date > mask_date:\n",
    "            paths_after.append(path)\n",
    "            clouds_nodata_after.append(clouds_perc + nodata_perc)\n",
    "        else:\n",
    "            paths_before.append(path)\n",
    "            clouds_nodata_before.append(clouds_perc + nodata_perc)\n",
    "    print(f\"{event_id}: {len(paths):2} S2 L2A paths, {len(paths_before):2} before, {len(paths_after):2} after, ({mask_date})\")\n",
    "    if len(clouds_nodata_before) > 0 and len(clouds_nodata_after) > 0:\n",
    "        print(f\" --> min nodata/clouds before: {min(clouds_nodata_before):5.1f}%, after: {min(clouds_nodata_after):5.1f}%\")\n",
    "    if len(paths_before) > 0 and len(paths_after) > 0:\n",
    "        s2_valid_data_events.append(event_id)\n",
    "        paths_after_.append(paths_after)\n",
    "        clouds_nodata_after_.append(clouds_nodata_after)\n",
    "        paths_before_.append(paths_before)\n",
    "        clouds_nodata_before_.append(clouds_nodata_before)\n",
    "len(s2_valid_data_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ea729-1840-4d0c-8768-3d9fa8ec30fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"event_id\": s2_valid_data_events, \n",
    "              \"paths_before\": paths_before_, \"clouds_nodata_before\": clouds_nodata_before_,\n",
    "                  \"paths_after\": paths_after_, \"clouds_nodata_after\": clouds_nodata_after_})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c31b8-bc8a-4211-aaae-000a2e9897a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def best_before_path(row):\n",
    "    # Take the earliest date with clouds < 10%\n",
    "    for clouds_nodata, path in zip(row[\"clouds_nodata_before\"], row[\"paths_before\"]):\n",
    "        if clouds_nodata < 10:\n",
    "            return path, clouds_nodata\n",
    "    # Take the earliest date with clouds < 30%\n",
    "    for clouds_nodata, path in zip(row[\"clouds_nodata_before\"], row[\"paths_before\"]):\n",
    "        if clouds_nodata < 30:\n",
    "            return path, clouds_nodata\n",
    "    # Take the earliest date with clouds < 100%\n",
    "    for clouds_nodata, path in zip(row[\"clouds_nodata_before\"], row[\"paths_before\"]):\n",
    "        if clouds_nodata < 100:\n",
    "            return path, clouds_nodata\n",
    "    # Else return the oldest path\n",
    "    return row[\"paths_before\"][0], row[\"clouds_nodata_before\"][0]\n",
    "\n",
    "def best_after_path(row):\n",
    "    # Take the latest date with clouds < 10%\n",
    "    for clouds_nodata, path in zip(row[\"clouds_nodata_after\"][::-1], row[\"paths_after\"][::-1]):\n",
    "        if clouds_nodata < 10:\n",
    "            return path, clouds_nodata\n",
    "    # Take the latest date with clouds < 30%\n",
    "    for clouds_nodata, path in zip(row[\"clouds_nodata_after\"][::-1], row[\"paths_after\"][::-1]):\n",
    "        if clouds_nodata < 30:\n",
    "            return path, clouds_nodata\n",
    "    # Take the latest date with clouds < 100%\n",
    "    for clouds_nodata, path in zip(row[\"clouds_nodata_after\"][::-1], row[\"paths_after\"][::-1]):\n",
    "        if clouds_nodata < 100:\n",
    "            return path, clouds_nodata\n",
    "    # Else return the newest path\n",
    "    return row[\"paths_after\"][-1], row[\"clouds_nodata_after\"][-1]\n",
    "    \n",
    "df[\"path_best_before\"] = df[[\"paths_before\", \"clouds_nodata_before\"]].apply(lambda row: best_before_path(row)[0], axis=1)\n",
    "df[\"path_best_after\"] = df[[\"paths_after\", \"clouds_nodata_after\"]].apply(lambda row: best_after_path(row)[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c371fb80-c4e4-474e-b4f3-92d7cd4e1c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clouds_nodata_best_before\"] = df[[\"paths_before\", \"clouds_nodata_before\"]].apply(lambda row: best_before_path(row)[1], axis=1)\n",
    "df[\"clouds_nodata_best_after\"] = df[[\"paths_after\", \"clouds_nodata_after\"]].apply(lambda row: best_after_path(row)[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659d8f8-bac0-4954-ad2a-db09fbc12ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_paths = []\n",
    "deforest_pxs = []\n",
    "for event_id in df[\"event_id\"].tolist():\n",
    "    label_path = glob.glob(f\"data/{event_id}/*_mask.tif\")[0]\n",
    "    label_paths.append(label_path)\n",
    "    label = tifffile.imread(label_path)\n",
    "    deforest_pxs.append((label == 255).sum())\n",
    "df[\"deforest_pxs\"] = deforest_pxs\n",
    "df[\"label_path\"] = label_paths\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e751faa-fc2e-4bee-b0f0-9792bdf7d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e592d-b61d-45db-8772-67027771fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 222221\n",
    "while True:\n",
    "    np.random.seed(seed)\n",
    "    folds = [0, 1, 2, 3, 4] * (len(df) // 5 + 1) #np.random.choice([0, 1, 2, 3, 4], size=len(df))\n",
    "    np.random.shuffle(folds)\n",
    "    df[\"fold\"] = folds[:len(df)]\n",
    "    # print(df[\"fold\"].value_counts())\n",
    "    std_counts = df.groupby(\"fold\")[\"deforest_pxs\"].sum().std().item()\n",
    "    # print(f'Seed {seed}: {df.groupby(\"fold\")[\"deforest_pxs\"].sum()}, Std = {std_counts:.0f}')\n",
    "    if std_counts < 2000:\n",
    "        break\n",
    "    seed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7c19b-3b11-4d07-9f4c-1e9e210cfda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    with rasterio.open(row[\"path_best_before\"]) as src:\n",
    "        output_path = row[\"path_best_before\"].replace(\".tif\", \"_uncompressed.tif\")\n",
    "        if not os.path.exists(output_path):\n",
    "            profile = src.profile\n",
    "            profile[\"compress\"] = None\n",
    "            with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "                dst.write(src.read())\n",
    "\n",
    "    with rasterio.open(row[\"path_best_after\"]) as src:\n",
    "        output_path = row[\"path_best_after\"].replace(\".tif\", \"_uncompressed.tif\")\n",
    "        if not os.path.exists(output_path):\n",
    "            profile = src.profile\n",
    "            profile[\"compress\"] = None\n",
    "            with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "                dst.write(src.read())\n",
    "\n",
    "df[\"path_best_before\"] = df[\"path_best_before\"].apply(lambda x: x.replace(\".tif\", \"_uncompressed.tif\"))\n",
    "df[\"path_best_after\"] = df[\"path_best_after\"].apply(lambda x: x.replace(\".tif\", \"_uncompressed.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17c3da-201d-4bae-bf1a-65f0c938e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"catalogues\", exist_ok=True)\n",
    "df.to_pickle(\"catalogues/2025_08_18_s2_single_last_after_img.pkl\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31198c-4d6b-4805-ba38-92daa8a9e612",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(\"fold\")[\"deforest_pxs\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c5b5d-84d4-42c3-8273-2c7e87d09650",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2121827-b2d5-4e0d-bd69-2b937c4f5dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_nb = \"S2_single_2-0\"\n",
    "path = \"catalogues/2025_08_18_s2_single_last_after_img.pkl\"\n",
    "hps_dict = {\n",
    "    ############\n",
    "    # Data\n",
    "    ############\n",
    "    \"df_path\": path,\n",
    "\n",
    "    ############\n",
    "    # Training\n",
    "    ############\n",
    "\n",
    "    ## Experiment Setup\n",
    "    \"name\": f\"Exp{exp_nb}\",\n",
    "\n",
    "    ## Model\n",
    "    \"num_classes\": 1,\n",
    "    \"input_channel\": 15,\n",
    "    \"backbone\": \"timm_efficientnet_b1\",\n",
    "    \"pretrained\": 1,\n",
    "    \"model\": \"unetplusplus\",\n",
    "\n",
    "    # Training Setup\n",
    "#     \"resume\": \"trained_models/Exp7-4/fold_0/2022-02-05_23-13-25/best_metric_18_0.9768.pt\",\n",
    "    \"print_freq\": 500,\n",
    "    \"use_fp16\": 0,\n",
    "    \"patience\": 8, #5,\n",
    "    \"epoch_start_scheduler\": 10,\n",
    "\n",
    "    # Optimizer\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.0,\n",
    "\n",
    "    ## Data Augmentation on CPU\n",
    "    \"train_crop_size\": 256 + 32 + 32,\n",
    "    \"train_batch_size\": 16, #32\n",
    "    \"cutmix_alpha\": 0,\n",
    "    \"da_brightness_magnitude\": 0.0,\n",
    "    \"da_contrast_magnitude\": 0.0,\n",
    "\n",
    "    # Data Augmentation on GPU\n",
    "    \"gpu_da_params\": [0.25],\n",
    "    \n",
    "    ### Loss, Metric\n",
    "    \"alpha\": 0.25,\n",
    "#     \"loss\": \"lovasz\",\n",
    "           }\n",
    "\n",
    "for fold_nb in range(0, 5):\n",
    "    hps = HyperParams(**hps_dict)\n",
    "    hps.fold_nb = fold_nb\n",
    "    num_batches = 250 // (hps.train_batch_size * torch.cuda.device_count())\n",
    "    # num_batches = 10\n",
    "    hps.num_batches = num_batches\n",
    "    train_dataset, train_loader, val_dataset, val_loader = get_dataloaders(hps)\n",
    "    # continue\n",
    "\n",
    "    best_metric, best_metric_epoch = train(hps, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0226b-0bfa-4601-9c28-317165de8d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
